{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-28T01:04:21.822451Z",
     "start_time": "2020-03-28T01:04:21.134742Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import time, datetime\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchsummary import summary\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, n_ch, n_cls):\n",
    "        super().__init__()\n",
    "        # RGB세개 1채널, 20개 특징 추출, filter 크기, stride 1\n",
    "        self.conv1_1 = nn.Conv2d(n_ch, 64, 3, 1, padding=1)\n",
    "        self.conv1_2 = nn.Conv2d(64, 64, 3, 1, padding=1)\n",
    "        self.conv1_bn = nn.BatchNorm2d(64)\n",
    "        self.maxp1 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.conv2_1 = nn.Conv2d(64, 64, 3, 1, padding=1)\n",
    "        self.conv2_2 = nn.Conv2d(64, 64, 3, 1, padding=1)\n",
    "        self.conv2_bn = nn.BatchNorm2d(64)\n",
    "        self.maxp2 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.conv3_1 = nn.Conv2d(64, 64, 3, 1, padding=1)\n",
    "        self.conv3_2 = nn.Conv2d(64, 64, 3, 1, padding=1)\n",
    "        self.conv3_bn = nn.BatchNorm2d(64)\n",
    "        self.maxp3 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.conv4_1 = nn.Conv2d(64, 64, 3, 1, padding=1)\n",
    "        self.conv4_2 = nn.Conv2d(64, 64, 3, 1, padding=1)\n",
    "        self.conv4_bn = nn.BatchNorm2d(64)\n",
    "        self.maxp4 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.dense1 = nn.Linear(2*2*64, 128)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.dense2 = nn.Linear(128, n_cls)  \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1_1(x))\n",
    "        x = F.relu(self.conv1_bn(self.conv1_2(x)))\n",
    "        x = self.maxp1(x)\n",
    "        x = F.relu(self.conv2_1(x))\n",
    "        x = F.relu(self.conv2_bn(self.conv2_2(x)))\n",
    "        x = self.maxp2(x)\n",
    "        x = F.relu(self.conv3_1(x))\n",
    "        x = F.relu(self.conv3_bn(self.conv3_2(x)))\n",
    "        x = self.maxp3(x)\n",
    "        x = F.relu(self.conv4_1(x))\n",
    "        x = F.relu(self.conv4_bn(self.conv4_2(x)))\n",
    "        x = self.maxp4(x)\n",
    "        # flatten\n",
    "        x = x.view(-1, 2*2*64)\n",
    "        feature = F.relu(self.dense1(x))\n",
    "        x = self.dropout1(feature)\n",
    "        x = self.dense2(x)\n",
    "        return x\n",
    "\n",
    "class SemblexTraining:\n",
    "    def __init__(self, Xs, lr, n_iter, model_name, GPU_idx):\n",
    "        self.Xs = Xs\n",
    "        self.lr = lr\n",
    "        self.n_batch = n_batch\n",
    "        self.n_iter = n_iter\n",
    "        self.model_name = model_name\n",
    "        self.GPU_idx = GPU_idx\n",
    "\n",
    "    def Reshape4torch(self, img):\n",
    "        \"\"\"\n",
    "        (sample #, height, width, channel) -> (sample #, channel, height, width)\n",
    "        \"\"\"\n",
    "        img = np.transpose(img, (0, 3, 1, 2))\n",
    "        return img\n",
    "    \n",
    "    def GenerateLabel(self, data, cls):\n",
    "        label = cls*np.ones([data.shape[0]])\n",
    "        return label\n",
    "    \n",
    "    def Split2TV(self, data, label, rate_t_v = 0.9):\n",
    "        data_num = len(data)\n",
    "        train_idx = np.random.choice(data_num, int(rate_t_v*data_num), replace = False)\n",
    "        valid_idx = np.setdiff1d(np.arange(data_num), train_idx)\n",
    "        return data[train_idx], label[train_idx], data[valid_idx], label[valid_idx]\n",
    "    \n",
    "    def Get_device(self, GPU_idx = 3):\n",
    "        self.device = torch.device(\"cuda:{}\".format(GPU_idx) if torch.cuda.is_available() else \"cpu\")\n",
    "        if cuda:\n",
    "            current_device = torch.cuda.current_device()\n",
    "            print(\"Device:\", torch.cuda.get_device_name(current_device))\n",
    "        else:\n",
    "            print(\"Device: CPU\")\n",
    "    \n",
    "    def Define_model_opt(self, n_ch, n_cls, lr = 0.00001):\n",
    "        self.model = ConvNet(n_ch, n_cls)\n",
    "        # model = model.cuda()\n",
    "        self.model = self.model.to(device)\n",
    "        # if device == 'cuda':\n",
    "        #     net = torch.nn.DataParallel(net)\n",
    "        #     cudnn.benchmark = True\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "        summary(self.model, (n_ch, 40, 40), device = self.device)\n",
    "         \n",
    "    def RandomMinibatch(self, data, label, n_batch = 100):\n",
    "        batch_idx = np.random.choice(len(data), n_batch, replace = False)\n",
    "        return data[batch_idx], label[batch_idx]\n",
    "    \n",
    "    def Shuffle(x1, x2):\n",
    "        \"\"\"\n",
    "        random shuffle of two paired data -> x, y = shuffle(x, y)\n",
    "        but, available of one data -> x = shuffle(x, None)\n",
    "        \"\"\"\n",
    "        idx = np.arange(len(x1))\n",
    "        np.random.shuffle(idx)\n",
    "        if type(x1) == type(x2):\n",
    "            return x1[idx], x2[idx] \n",
    "        else:\n",
    "            return x1[idx]\n",
    "        \n",
    "    def Torch_Minibatch_Load(self, Xs, Ys, batch_size = 100, shuffle = False):\n",
    "        x, y = [], []\n",
    "        for X, Y in zip(Xs, Ys):\n",
    "            x_i, y_i = RandomMinibatch(X, Y, batch_size)\n",
    "            x.append(x_i), y.append(y_i)\n",
    "        x, y = np.concatenate(x), np.concatenate(y)\n",
    "        if shuffle != False:\n",
    "            x, y = shuffle(x, y)\n",
    "        x, y = torch.tensor(x, device=device).float(), torch.tensor(y, device=device).long()\n",
    "        return x, y\n",
    "        \n",
    "    def Training_Process(self, n_iter, batch_size, model_name, save_path = './model/'):\n",
    "    \n",
    "        self.loss_hist, self.accr_hist = [], []\n",
    "        self.val_loss_hist, self.val_accr_hist = [], []\n",
    "\n",
    "        iter_i = 0\n",
    "\n",
    "        while True:\n",
    "            iter_i += 1\n",
    "\n",
    "            train_x, train_y = Torch_Minibatch_Load(self.train_Xs, self.train_Ys, batch_size, shuffle = True)\n",
    "\n",
    "            output = model(train_x)\n",
    "            loss = criterion(output, train_y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if iter_i % 10 == 0:\n",
    "\n",
    "                _, pred = torch.max(output, 1)\n",
    "\n",
    "                self.loss_hist.append(loss.tolist())\n",
    "                self.accr_hist.append((torch.sum(pred == train_y.data).tolist() / len(train_y)))\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    valid_x, valid_y = Torch_Minibatch_Load(self.valid_Xs, self.valid_Ys, batch_size)\n",
    "\n",
    "                    valid_output = model(valid_x)\n",
    "                    valid_loss = criterion(valid_output, valid_y)\n",
    "\n",
    "                    _, valid_pred = torch.max(valid_output, 1)\n",
    "\n",
    "                    self.val_loss_hist.append(valid_loss.tolist())\n",
    "                    self.val_accr_hist.append((torch.sum(valid_pred == valid_y.data).tolist() / len(valid_y)))\n",
    "\n",
    "\n",
    "                print(\"{:05d} | train_loss: {:.5f}, train_accr: {:.3f} | val_loss: {:.5f}, val_accr: {:.3f}\".format(iter_i, \n",
    "                                                                                                                    self.loss_hist[-1], \n",
    "                                                                                                                    self.self.accr_hist[-1], \n",
    "                                                                                                                    self.val_loss_hist[-1], \n",
    "                                                                                                                    self.val_accr_hist[-1]))\n",
    "\n",
    "                if iter_i >= 100:  \n",
    "        #             if np.mean(val_loss_hist[-5 :]) >= np.mean(val_loss_hist[-10:]):\n",
    "        #                 print('')\n",
    "        #                 print('Early stopping!!')\n",
    "        #                 print('..val_loss (avg. within 5): {:.5f} >= val_loss (avg. within 10) {:.5f}'.format(np.mean(val_loss_hist[-5 :]),\n",
    "        #                                                                                                   np.mean(val_loss_hist[-10:])))\n",
    "\n",
    "                    if val_loss_hist[-1] == np.min(val_loss_hist):\n",
    "                        now = datetime.datetime.now()\n",
    "                        nowDatetime = now.strftime('%y%m%d%H%M')\n",
    "                        model_full_name = '{}_AB_{}_{:05d}_loss_{:.6f}_val_loss_{:.6f}.pt'.format(model_name, nowDatetime, iter_i, \n",
    "                                                                                             np.mean(loss_hist[-3:]),\n",
    "                                                                                             np.mean(val_loss_hist[-3:]))\n",
    "                        \n",
    "                        \n",
    "                        Generate_folder(save_path)\n",
    "                        torch.save(model.state_dict(), save_path + model_full_name)\n",
    "        #                 break  \n",
    "                if iter_i == n_iter:\n",
    "                    break\n",
    "                    \n",
    "    def PlotHIST(self, model_name, save_path = './results/npy/'):\n",
    "        \n",
    "        fig = plt.figure(figsize = (15,30))\n",
    "        plt.suptitle('Training hist', y = 0.92, fontsize = 20)\n",
    "\n",
    "        # x_axis = range(1, 10*len(accr_hist)+1, 10)\n",
    "        x_axis = np.arange(10, 10*len(self.accr_hist)+1, 10)\n",
    "\n",
    "        plt.subplot(2, 1, 1)\n",
    "        plt.plot(x_axis, self.accr_hist, 'b-', label = 'Training Accuracy')\n",
    "        plt.plot(x_axis, self.val_accr_hist, 'r-', label = 'Validation Accuracy')\n",
    "        plt.xlabel('Iteration', fontsize = 15)\n",
    "        plt.ylabel('Accuracy', fontsize = 15)\n",
    "        plt.legend(fontsize = 10)\n",
    "        plt.grid('on')\n",
    "        plt.subplot(2, 1, 2)\n",
    "        plt.plot(x_axis, self.loss_hist, 'b-', label = 'Training Loss')\n",
    "        plt.plot(x_axis, self.val_loss_hist, 'r-', label = 'Validation Loss')\n",
    "        plt.xlabel('Iteration', fontsize = 15)\n",
    "        plt.ylabel('Loss', fontsize = 15)\n",
    "        # plt.yticks(np.arange(0, 0.25, step=0.025))\n",
    "        plt.legend(fontsize = 12)\n",
    "        plt.grid('on')\n",
    "        plt.show()\n",
    "        \n",
    "        Generate_folder(save_path)\n",
    "        \n",
    "        np.save(save_path + '{}_accr_hist'.format(model_name), accr_hist)\n",
    "        np.save(save_path + '{}_val_accr_hist'.format(model_name), val_accr_hist)\n",
    "        np.save(save_path + '{}_loss_hist'.format(model_name), loss_hist)\n",
    "        np.save(save_path + '{}_val_loss_hist'.format(model_name), val_loss_hist)\n",
    "        \n",
    "    def Run(self, model_dir, hist_dir):\n",
    "        Xs = []\n",
    "        for i, X in zip(range(self.n_cls), self.Xs):\n",
    "            X = self.Reshape4torch(X)\n",
    "            Y = self.CreateLabel(X, i)\n",
    "            train_X, train_Y, valid_X, valid_Y = self.Split2TV(X, Y, rate_t_v = 0.9)\n",
    "            train_Xs.append(train_X), train_Ys.append(train_Y)\n",
    "            valid_Xs.append(valid_X), valid_Ys.append(valid_Y)\n",
    "        self.train_Xs, self.train_Ys = np.concatenate(train_Xs), np.concatenate(train_Ys)\n",
    "        self.valid_Xs, self.valid_Ys = np.concatenate(valid_Xs), np.concatenate(valid_Ys)\n",
    "        self.Get_device(self.GPU_idx)\n",
    "        self.Define_model_opt(self.n_ch, self.n_cls, self.lr)\n",
    "        self.Training_Process(self.n_iter, self.batch_size, self.model_name, save_path = './model/')\n",
    "        self.PlotHIST(self.model_name, save_path = './results/npy/')    "
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
